---
title: "Untitled"
author: "becarios precarios"
date: "2 de mayo de 2018"
output: word_document
---

```{r setup, include=FALSE}
medidas <- c(6, 3, 6, 5, 6, 3, 6, 4, 5, 2, 7, 5, 6, 7, 10, 7, 4, 6, 7, 7, 11, 8, 7, 9, 7, 9, 8, 8, 11, 9)
grupo <- rep(c("A","B","C"),c(10,10,10))
datos1=data.frame(medidas, grupo)
medidas.A=medidas[1:10]
medidas.B=medidas[11:20]
medidas.C=medidas[21:30]

attach(datos1)
```


```{r}
par ( mfrow = c (1 ,3))
plot(density(medidas.A),main="Grupo A")
plot(density(medidas.B),main="Grupo B")
plot(density(medidas.C),main="Grupo C")

```


Otra opción es usar un ANOVA para comparar las medias de forma simultanea. Este metodo tiene 3 condiciones de aplicabilidad que debemos comprobar antes de usarlo:

- Homocedasticidad. Las varianzas deben ser similares para todos los grupos. Ya en el análisis descriptivo vimos que estas eran muy similares.

- Normalidad. Los datos deben comportarse como una normal. A pesar de saber que nuestros datos son una Poisson, podemos aproximarlos mediante una normal.

- Independencia de los datos. Esta hipotesis la tomaremos como cierta confiando en que el investigador ha seleccionado los dientes de forma aleatoria.

Vamos a comprobar el cumplimiento de las condiciones. Primero comprobaremos la homocedasticidad:

```{r}
bartlett.test(medidas,grupo)
```

El test de Barlett nos indica que las varianzas son muy similares (algo que ya sabiamos).
Ahora para comprobar la normalidad de los datos dentro de cada grupo usaremos el comando shapiro.test:

```{r}
shapiro.test(medidas.A)
shapiro.test(medidas.B)
shapiro.test(medidas.C)
```


Vemos que los p-valores son superiores a 0.05, por lo que podremos suponer normalidad en nuestros datos (aunque por definición sepamos que se trata de datos Poisson).
Ahora podemos usar el modelo ANOVA de efectos fijos para comparar las medias:

```{r}
modelo = aov(medidas~grupo)
summary.aov(modelo)
```

En la salida de R podemos ver que el p-valor es muy bajo, por lo que se rechazara que las medias sean iguales.

Una vez hecho el modelo lo validaremos para ver si es correcto aplicarlo.

```{r}
par ( mfrow = c (1 ,3))

plot ( modelo )

```
En la gráfica Normal Q-Q esperariamos que los puntos se ajustasen a la recta (esto pasaria si los errores fuesen normales).
En la tercera grafica debemos ver que los errores estandarizados estan entre -2 y 2. Que es así.

Tal y como era de esperar, a la hora de validar el modelo fallamos en la normalidad.


Podemos usar un test no parametrico para comparar las medianas de nuevo (vuelvo a insistir, no es lo mismo media que mediana, no hay que equivocarse en lsa conclusiones).
Lo haremos con el siguiente comando:
```{r}
grup=rep(c(1,2,3),c(10,10,10))
kruskal.test(medidas,grup)
```

Con este test no parametrico vemos que descartamos que las medianas sean iguales.

